---
title: "Evaluation - Step By Step"
author: "jp"
date: "3/8/2020"
output:
  html_notebook: default
  html_document:
    toc: yes
    toc_float: yes
    code_folding: show
  word_document:
    toc: yes
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( echo = TRUE, cache = TRUE )
```

 
```{r packages, include= FALSE}

# install.packages("fabletools", repos = "https://tidyverts.org")
library( fabletools )
library( tsoutliers )
library( brolgar )
library( tsoutliers )
library( tsbox )
library( CausalImpact ) # loads MASS, which causes conflict with
library( anomalize )
library( tibbletime )
library( dygraphs )

library( readxl )

library( fpp3 ) # tsibbledata, feasts, fable, tsibble all-in one
library( GGally )
library( plotly )
library( sugrrants )

# Parallelization
# library(furrr)
# library( future.apply )
# plan(multiprocess)
library( sf )
library( mapview )
library( tidyverse)
library( scales )

```

# 1. Define data

Use [dataDictionary tool](https://ddarko.shinyapps.io/dhis2_dictionary/) to identify key variables, request data for each month of last 5 years, and download the excel file with data.  With function s1, read in the data. Repeat these steps as necessary to get all relevent variables. For example, download variables that comprise confirmed cases, RDT stockouts, attendance, etc.


# 2. Request data

Prepare table with requested data and file names. 

TODO: include number of confirmatory tests, and consider adjusting tested rate as explanatory variable in time-series models.

```{r data_requests}

data_requests = tribble( 
    ~name , ~file ,
    'districtRain' , 'malawi_arc.rds' ,
    'stockouts' , 'Malawi_RDT Stock outs_2020-01-28.xlsx' ,
    'confCases' , 'Malawi_confirmed cases ipd, opd, and chw_2020-02-29.xlsx' ,
    'attendance' , 'Malawi_OPD Attendance_2020-03-14.xlsx' ,
    'metadata' , 'malawi_metaData_2020-03-04.xlsx'
)
    
```


```{r, s2}

s2 = function( data_requests , folder ){
    
    for ( i in 1:nrow( data_requests )){
        
        print( data_requests$file[i] )
        
        if ( grepl( '.xlsx' , data_requests$file[i] ) &
             !grepl( 'metadata' , data_requests$file[i] , ignore.case = TRUE ) 
             ){
            
            path = paste0( folder, data_requests$file[i] )
            name = data_requests$name[i]
            
            # summary data
            assign( name , read_excel( path , 'summaryData')  %>%
                        filter( Count.max != 0 )  %>%
                        mutate( !! name := as.integer( sum ) ) %>%
                        select( orgUnit, orgUnitName , period, !! name ) ,
                    envir = .GlobalEnv )
            
            # formula elements
            x = read_excel( path , 'formulaData')  %>%
                unite( 'de' , dataElement, Categories , remove = TRUE ) 
                       
            x.  = x %>% 
                mutate( SUM = as.integer( SUM ) ) %>%
                pivot_wider( id_cols = c(orgUnit , orgUnitName , period ), 
                                     names_from = de , 
                                     values_from = SUM
                                     )
            
            if ( x$de %>% unique %>% length > 1 ){
                assign( paste0( name, 'x') , x. , envir = .GlobalEnv )
            }
            
        }
        
        if ( grepl( 'metadata' , data_requests$file[i] , ignore.case = TRUE ) ){
            print( 'orgUnits and orgUnitLevels' )
            path = paste0( folder, data_requests$file[i] )
            assign( 'orgUnits' , read_excel( path , 'OrgUnits'  ) , 
                    envir = .GlobalEnv )
            assign( 'OrgUnitLevels' , read_excel( path , 'OrgUnitLevels'  ) , 
                    envir = .GlobalEnv )
        }
        
        if ( grepl( 'arc|rain' , data_requests$file[i] , ignore.case = TRUE ) ){
            
            path = data_requests$file[i] 
            name = data_requests$name[i]
            assign( name , readRDS( path ) ,
                    envir = .GlobalEnv )

        }
        
    }
}

```


```{r s2_example}

folder = '../dataDictionary/dhis2_dictionary/Formulas/'

s2( data_requests , folder )


stockoutsx = stockoutsx %>%
    mutate_at( vars( contains('stock') ) ,  ~ifelse(.x > 31 , NA, .x ) )

```

```{r combine_datasets }

datasets = c( "stockouts" , "confCases" , "stockoutsx" , "confCasesx" , "attendance" ) 

dataset = get( datasets[1]  ) 
for (i in 2:5){
    dataset = full_join( dataset , get( datasets[i]  ) ,
                         by = c( 'orgUnit' , 'orgUnitName' , 'period' ) )
}

parent =  left_join( orgUnits %>% select(levelName, id, parent)  ,
                     orgUnits %>% select( id, name) %>% rename( parentName = name ) ,
                     by = c('parent' = 'id' ) 
) %>%
    left_join( orgUnits %>% select(levelName, id ) %>% rename(parentLevel = levelName ) , 
               by = c('parent' = 'id' ) 
               )


d = left_join( dataset , parent %>% select( id, parent , parentName ) , 
                     by = c('orgUnit' = 'id' )) %>%
    mutate( period = zoo::as.yearmon( period, "%Y%m") %>%
                    yearmonth( . )  ) %>%
    left_join( districtRain %>% 
                 select( month , orgUnit , avg_month ) %>%
                 rename( rain = avg_month ) %>%
                 group_by( orgUnit, month ) %>%
                 mutate( rain_lag = lag( rain ) ), 
               by = c( 'parent' = 'orgUnit' , 'period' = 'month' ) )

# glimpse( d )
# View( d )
```

# 3. Convert data to time-series

```{r data_set_to_ts}

dTs = d %>% 
    mutate( period = yearmonth( period ) ) %>%
    as_tsibble( index =  period, 
                        key = c(orgUnit, orgUnitName, parent, parentName) 
                        ) %>%
    # index_by( year_month = yearmonth( month ) ) %>%
    fill_gaps()

# measures( dTs )
# interval( dTs )

```

# 4. Calculate data counts

```{r s4_nonMissing}


nonMissing = dTs %>% as_tibble %>% 
    group_by( orgUnit ) %>% 
    mutate( interval = 1L ) %>%
    summarise_if( is.integer , funs( sum(!is.na(.)) ) ) %>% 
    arrange(attendance) 

# View( nonMissing )


```

```{r  nonMissing_chart1}
nonMissing %>% 
    pivot_longer(- orgUnit,  names_to = 'var' , values_to = 'val') %>%
    ggplot +
    geom_histogram( aes( y = val ) , binwidth = 1) +
    facet_wrap( ~ var , ncol = 2 ) +
    labs( title = 'Number of non-missing values in the last 5 years' ,
          subtitle = 'maximum of 61 months' )
    

```

```{r nonMissing_chart2}

nonMissing[,] %>% 
    ungroup() %>%
    pivot_longer(- orgUnit,  names_to = 'var' , values_to = 'val') %>%
    arrange( var  ) %>%
    ggplot +
    geom_line( aes( x = var , y = val , group = orgUnit), alpha = .2 ) +
    coord_flip()
    
```

## 4a. Compare counts with form submissions

# 5. Classify facilities by amount of data available/reported

classify those that have at 36 months ('three years worth') or more non-missing values for each 'high-frequency' variable.  High-frequency variables are those where at least half of all facilities submit this variable at least 66% of the time.   Note: the 36 months are not necessarily 36 continuous months. 

```{r minNumFacilities}

# number of intervals
maxInterval = dTs %>% as_tibble %>% group_by(orgUnit) %>% 
    summarise( n = n()) %>% pull(n) %>% max

nonMissing = dTs %>% as_tibble %>% 
    group_by( orgUnit ) %>% 
    mutate( intervals = 1L ) %>%
    summarise_if( is.integer , funs( sum(!is.na(.)) ) ) %>% 
    arrange(attendance) 

highFreqCols = function( df , pct.months.cutoff = 0, pct.facilities.cutoff = 0 ){
    map_df( df , ~sum( .x >= pct.months.cutoff * maxInterval ) ) %>% 
        t %>% as.data.frame() %>%
        rename( nOrgUnits = V1 ) %>% 
        rownames_to_column( 'Variable' ) %>% 
        filter( nOrgUnits >= pct.facilities.cutoff * nrow(df) ) %>%
        pull( Variable )
}

# highFreqCols(nonMissing, .66 , .5) 

# excluding 
# ex = 'OpenLMIS MAL Malaria Rapid Diagnostic Test (MRDT) Kits Stock out days_default'
# 
# colisnum = map_lgl( nonMissing, is.numeric )
# colsToCount = setdiff( colnames( nonMissing )[colisnum],  ex )

minNumFacilities = function( df , cutoff = 0 , cols ){
    # set non numeric cols to 1 
    isNum = map_lgl( df[, cols ], is.numeric)
    df[, cols[!isNum] ] = nrow( df )
    d = df[, cols ]
    
    d %>% 
    mutate( minNonMiss = pmap( d , min) >= cutoff ) %>%
    summarise( minNumFacilities = sum( minNonMiss )) %>%
    pull( minNumFacilities )
}

minNumFacilities( nonMissing , 36 , highFreqCols(nonMissing, .66 , .5) )

map_int( 0:maxInterval , 
         ~minNumFacilities( nonMissing , .x , highFreqCols(nonMissing, .66 , .5)  )
         )
# number of facilities with x months of data for key variables
map_int( c(0, 24, 36, 48, 60 ) , 
         ~minNumFacilities( nonMissing , .x , highFreqCols(nonMissing, .66 , .5)  )
         )

# number of facilities with x months of data for all variables
map_int( c(0, 24, 36, 48, 60 ) , 
         ~minNumFacilities( nonMissing , .x , highFreqCols(nonMissing)  )
         )
```

# 6. Filter to those with at least 36 months reported

```{r s6}

selectMinNumFacilities = function( df , cutoff = 0 , cols = NA ){
    
    if ( all( is.na( cols ) ) )   cols = colnames( df )
    isNum = map_lgl( df[, cols ], is.numeric)
    
    df %>% 
    mutate( minNonMiss = pmap( df[, cols[isNum] ] , min ) %>% unlist ) %>%
    filter( minNonMiss >= cutoff ) %>%
    pull( orgUnit )
}

# data36 = selectMinNumFacilities( nonMissing , 36 ) # all cols

data36facilities = selectMinNumFacilities( nonMissing , 36 , 
                                 highFreqCols( nonMissing, .66 , .5) # high freq cols 
                                 ) 

cat( 
  'Of the' ,
  comma( nrow( nonMissing) ) ,
  'facilities reporting,' ,
  length( data36facilities ), 
  '(' , percent( length( data36facilities ) / nrow( nonMissing ) ) , ')' ,
  'facilities had the minimum amount of data reported.' 
  )
```


# 7. Calculate 'fitness' and classify facilities 

Categorize as 

- 'low info' when facilities have <36 months data for key variables
- 'med info' when facilities have modeled MAPE > 25% 
- 'high info' when facilities have modeled MAPE <= 25% 

```{r low_information_facilties}

lowInfoFacilities = setdiff( dTs$orgUnit , data36facilities )

dTs.36 = dTs %>% filter( orgUnit %in% data36facilities )

```

## 7a. Identify outliers and replace  

## 7b. Interpolate missing values Outliers  (saved)

```{r cols}

# key( dTs.36 ) 
keyCols = c( 'orgUnit', 'orgUnitName', 'parent', 'parentName' )
cols = setdiff( names( dTs.36 ), c( keyCols , 'period', 'rain', 'geometry') )

```

```{r clean , eval = FALSE }
clean = function( x ,  ... ){ 
    # print('X'); print( x )
    # glimpse(x) 
  
    # pre clean extreme values
    meanVal = mean( x , na.rm = TRUE )
    # se <- function(x) sqrt( var(x , na.rm = TRUE )/ length( !is.na(x) ))
    sdVal = sd( x , na.rm = TRUE )
    x[ x > ( meanVal + 10 * sdVal ) ] = NA 

    # If all values < 100, do not impute or look for outliers; process unreliable
    if ( all( x < 50 | is.na( x ) ) ) return( x )
     
    # convert to time-series
    x.ts = x %>% as.ts(. , frequency = 12 ) 

    lambda = .5 # series with mostly low values have all outliers

    clean = 
    suppressMessages(
     forecast::tsclean( x.ts , replace.missing = TRUE, lambda = lambda ) %>%
       as.integer()
    )
    
    return( clean )
}

# clean all vars...
tictoc::tic("start")
dTs.36.clean =  
  suppressMessages( 
    dTs.36 %>% 
      group_by( orgUnit, orgUnitName, parent, parentName ) %>%
      # filter( orgUnit %in%  c( 'vGbcjNT1TSJ' , 'qzGX4XdWufs' ) ) %>%
      mutate_at( cols , clean ) %>%
      # mutate_at( vars(stockouts) , clean ) %>%
      ungroup()
  )
tictoc::toc()

saveRDS( dTs.36.clean , 'MalawiPBO/dTs.36.clean.rds')
```


```{r clean_review}

dTs.36.clean = readRDS( 'MalawiPBO/dTs.36.clean.rds' )

est = dTs.36.clean
actual = dTs.36  # %>% filter(orgUnit %in% c( 'vGbcjNT1TSJ' , 'qzGX4XdWufs' ) ) 

#Imputation added values for 
numberImputed = sum(is.na( actual[, cols])) - sum(is.na( est[, cols])) 

# subtract actual from estimate (after substituting zero for NA )
noNaActual = actual[, cols ] ; noNaActual[ is.na( noNaActual )] = 0
noNaEst = est[, cols ] ; noNaEst[ is.na( noNaEst ) ] = 0
diff =  noNaEst - noNaActual
diff = diff %>% mutate_all( as.integer )

est_actual = bind_cols( actual[, c( 'period' , 'orgUnit', 'orgUnitName', 'parent', 'parentName' , 'rain' )] , diff)

sumPosOnly = function(x) sum( x[x>0], na.rm = TRUE ) 
sumNegOnly = function(x) sum( x[x<0], na.rm = TRUE ) 
# View( est_actual )
# positive values represent interpolated values
interpolateEffect = est_actual %>% summarise_at( cols , sumPosOnly )  
    # as_tibble() %>%  summarise_at( cols , sum ) # total amnt for each var

# negative values are reductions of outliers
outlierEffect = est_actual %>% summarise_at( cols , sumNegOnly )
  # as_tibble() %>%  summarise_at( cols , sum ) # total amnt for each var

# Custom legend
leg = data.frame(ll = sort(c("Added through interpolattion","Removed identified outliers","Actual", "Adjusted")))

map( syms(cols) ,  ~ autoplot( interpolateEffect , !!.x  , color = 'blue' ) +
       labs( title = .x )  +
       autolayer( outlierEffect , !!.x , color = 'red' ) +
       autolayer( actual %>% summarise_at( cols , sum, na.rm = TRUE ) , !!.x )  +
       autolayer( est %>% summarise_at( cols , sum, na.rm = TRUE ) , !!.x , color = 'green' ) +
       scale_color_manual(values=c("blue", "red", "black", "green"), 
                       # name="Experimental\nCondition",
                       # breaks=c("ctrl", "trt1", "trt2"),
                       labels=c("Added through interpolattion","Removed identified outliers","Actual", "Adjusted"))
)
```

In 2015, the number of cases for "NMCP IPD Confirmed Malaria Cases_<5Yrs" is greatly reduced.  What is going on?  Looks like there could have been peak in cases from many facilities, but it turns out that about half of these cases came from one facility. Note that the red line, representing numbers removed as outliers, shows large reduction for one month in 2015 .   

```{r show_outlier_example}
col = syms("NMCP IPD Confirmed Malaria Cases_<5Yrs")

topOU = est_actual %>% arrange( `NMCP IPD Confirmed Malaria Cases_<5Yrs` ) %>%
  filter( row_number() == 1 ) %>% pull( orgUnit )

topOU.name = dTs.36 %>% filter( orgUnit %in% topOU ) %>% as_tibble() %>%
                      select( orgUnitName, parentName )  %>% 
                      unique %>% paste( collapse = ' , ')

dTs.36 %>% filter( orgUnit %in% topOU ) %>%
  autoplot( . ,`NMCP IPD Confirmed Malaria Cases_<5Yrs` , na.rm = TRUE ) +
  labs( title = paste( topOU.name ) , 
        subtitle = "NMCP IPD Confirmed Malaria Cases_<5Yrs" ) 
```


```{r test_clean, eval=FALSE}

.x = 6 # orgUnit ... 1:length(data36facilities) 
.c = 15 # columns...8:15

test.tsclean = function( .x , .c ){
 
  test.ts= dTs.36 %>%
    filter( orgUnit %in% data36facilities[ .x ] ) %>%
    select( period , cols[.c] )  %>%
    as.ts 
  
  if ( all( test.ts == 0 | is.na(test.ts) ) ) return( ggplot() )

  test.tsclean = forecast::tsclean( test.ts , 
                                  replace.missing = TRUE, lambda = 'auto')

  autoplot( test.ts %>% as_tsibble(), value  , na.rm=TRUE ) + 
    autolayer( test.tsclean %>% as_tsibble() , value, na.rm=TRUE ,
               color = 'red', alpha =.5 ) +
    labs( title = cols[.c] , 
          subtitle = d %>% filter( orgUnit == data36facilities[ .x ] ) %>%
                                        select( parentName, orgUnitName ) %>%
            unique %>% paste(collapse = ' , ')
          ) 
  
}

test.tsclean( 6, 2 ) 

# compare confCases with sub groups
gridExtra::grid.arrange( test.tsclean( .x, 2 )  , test.tsclean( .x, 5 ) ,
                         test.tsclean( .x, .x ) , test.tsclean( .x, 7 ) ,
                         test.tsclean( .x, 8 )  , test.tsclean( .x, 9 ) ,
                         test.tsclean( .x, 10 )  , test.tsclean( .x, 11 )  ,
                         test.tsclean( .x, 12 )  , test.tsclean( .x, 13 ) ,
                         # test.tsclean( .x, 14 )  , test.tsclean( .x, 15 ) ,
                         ncol = 2 
)
```


```{r outs, eval=FALSE}
outs = map( 1, # 1:length( data36facilities ) ,
  ~ dTs.36 %>%
  filter( orgUnit %in% data36facilities[ .x ] ) %>%
  select( period , confCases)  %>%
  as.ts %>%
  tsoutliers::tso( . , tsmethod = "auto.arima")
)
```

## 7.C Re-combine key variables (e.g. confCases, stockouts )

```{r re-combine }

confCasesCols = names( dTs.36.clean )[8:16 ]
confCasesFormula = paste( paste0("`" , confCasesCols , "`"), collapse = ' + ' )

stockoutCols = names( dTs.36.clean )[6:7 ]
stockoutColsFormula = paste( paste0("`" , stockoutCols , "`"), collapse = ' + ' )

dTs.36.new =
  dTs.36.clean %>% 
  # confCases
  mutate_at( confCasesCols , replace_na , 0 ) %>%
  mutate( 
    confCasesNew = eval( parse( text  = confCasesFormula ) )
    ) %>%
  # stockouts 
  mutate_at( stockoutCols , replace_na , 0 ) %>%
  mutate( 
    stockoutsNew = eval( parse( text  = stockoutColsFormula ) )
    ) %>%
 
  # remove unsused cols
   select( - confCasesCols , - stockoutCols ) 

```

```{r re-combine-chart}

compareOldNew = 
  dTs.36.new %>% 
  select( confCases , confCasesNew , orgUnit, period  ) %>%
  summarise_if( is.numeric , sum , na.rm = TRUE) %>%
  pivot_longer( -period, names_to = 'var' , values_to = 'val' ) %>%
  as_tsibble( index = period, key = var )

compareOldNew %>% autoplot( val  ) +
  labs( x = '', y = '', title = 'Combining Confirmed Case Counts from All Facilties: Actual vs Adjusted' ,
        subtitle = 'Adjusted: Removed outliers and imputed missing values'
        ) +
  scale_color_manual( "Confirmed Cases", values = c('black','green' ),
                        labels = c('Actual', 'Adjusted'))


```


Model each *newly* aggregated series at facility level (saved)

```{r train.fit , eval=FALSE}

pb = progress_estimated( length( cols ) )

cols = c( 'stockoutsNew' , 'attendance' , 'confCasesNew' )

fit.test = map( syms(cols) , 
              ~ dTs.36.new %>%
                  # filter( orgUnit %in% data36facilities[1:2] ) %>%
                  model( 
                    !! .x := 
                      # ETS(  box_cox( !! .x  , lambda = .5 ) ) 
                      ARIMA( box_cox( !! .x , lambda = .5 ) ~
                            pdq(0:1,0:1,0:1) + PDQ(0:1,0:1,0:1) )
                  )
              ) %>% 
  reduce( . , inner_join , by = keyCols )

saveRDS( fit.test , 'MalawiPBO/fit.test.rds' )
```

functions for decompose metrics 

```{r decomp_functions}

  # get remainder formn stl 
  decomp_method = function( .mable ){
      
      modelCols = setdiff( colnames( .mable ) , key( .mable ) )
   
      # m = map( 1:length(models) , 
      #             ~ maple %>%
      #             pull( !! models[ .x ] ) %>% 
      #             map( 'fit' )  %>% 
      #             map( 'method' ) %>% unlist() 
      # ) 
      
      # model = .mable[, modelCols[.x] ]
      
      map_chr( 1:length( modelCols ) , 
               
               ~.mable[, modelCols[.x] ] %>% 
                 map( 1 ) %>%
                   map( 'fit' )  %>% 
                   map( class ) %>% unlist
              
           )
  
  }
  
  has_remainder = function( .mable ){

      ifelse( 
         any( 
         grepl('stl', decomp_method( .mable ) , 
               ignore.case = TRUE ) 
          ) 
      ,
              TRUE ,
              FALSE
      )
  }
  
  
  decomp_remainder = function( .mable ){
    if ( has_remainder( .mable ) ){
      .mable %>%
      pull( stl ) %>% 
      map( 'fit' )  %>% 
      map( 'decomposition' ) %>% 
        map( 'remainder' ) %>% 
        unlist()
    } else { NA }
  }
  
```


Get fitted values for model 

```{r confCases.fit }

fit.test = readRDS( 'MalawiPBO/fit.test.rds' )

confCases.fit = map( 1:nrow( fit.test ) , 
                     ~ fit.test[ .x , 'confCasesNew' ] %>% 
                       augment()  %>%
                       mutate( orgUnit = fit.test[ .x , ]$orgUnit )
                     ) %>% rbind_list() 

```

For each facility, calculate the difference between actual confCasesNew and the fitted values.  Then, summarise with the sd, the mean absolute difference (MAPE), and the mean percent difference (MPE)

```{r MAPE_info_facilities }

# non-STL !! LONG - convert to function with progress bar
rsd.all = confCases.fit  %>% 
                 mutate( pe = log( confCasesNew + 1 ) - log( .fitted + 1 )   
                         ) %>%
                 as_tibble %>% 
                 group_by( orgUnit) %>%
                 summarise( 
                     sd_remainder = var( .resid ,
                                         na.rm = TRUE )^.5 ,
                     
                     mape = mean( abs( pe ) , na.rm = TRUE ) ,
                     mpe =  mean( pe , na.rm = TRUE )
                     )
        
ggplot( rsd.all , aes( mpe, mape  ) ) +
  geom_point()

rsd.all %>% 
  # group_by( .model ) %>% 
  do( tidy(summary( .$sd_remainder )) )

rsd.all %>% 
  # group_by( .model ) %>% 
  do( tidy(summary( .$mape )) )

ggplot( rsd.all  ) +
  geom_histogram( aes( sd_remainder ) , binwidth = .025 ) + theme_bw()+
    labs( title = 'sd_remainder')

ggplot( rsd.all ) +
  geom_histogram( aes( mape ) , binwidth = .025) + theme_bw() +
    labs( title = 'MAPE')

# Mean Percent Error
ggplot( rsd.all  ) +
  geom_histogram( aes( mpe ) , binwidth = .025) + theme_bw() +
    labs( title = 'MPE')
```


```{r MAPE_info_facilities_old, eval=FALSE}

# non-STL !! LONG - convert to function with progress bar
rsd.all = map( i , ~fit.test  %>% 
               filter( orgUnit %in% data36facilities[ .x ] ) %>% 
                # select( -stl ) %>%
                 augment() %>% 
                 mutate( pe = log( confCases + 1 ) - log( .fitted + 1 )   
                         ) %>%
                 as_tibble %>% 
                 group_by( orgUnit, .model ) %>%
                 summarise( 
                     sd_remainder = var( .resid ,
                                         na.rm = TRUE )^.5 ,
                     
                     mape = mean( abs( pe ) , na.rm = TRUE ) ,
                     mpe =  mean( pe , na.rm = TRUE )
                     )
        ) %>% 
  bind_rows()

ggplot( rsd.all , aes( sd_remainder, mape , group = .model ) ) +
  geom_point()

rsd.all %>% 
  group_by( .model ) %>% 
  do( tidy(summary( .$sd_remainder )) )

rsd.all %>% 
  group_by( .model ) %>% 
  do( tidy(summary( .$mape )) )

ggplot( rsd.all %>% filter(.model == 'arima' ) ) +
  geom_histogram( aes( sd_remainder ) , binwidth = .025 ) + theme_bw()+
    labs( title = 'sd_remainder')

ggplot( rsd.all %>% filter(.model == 'arima' ) ) +
  geom_histogram( aes( mape ) , binwidth = .025) + theme_bw() +
    labs( title = 'MAPE')

# Mean Percent Error
ggplot( rsd.all %>% filter(.model == 'arima' ) ) +
  geom_histogram( aes( mpe ) , binwidth = .025) + theme_bw() +
    labs( title = 'MPE')
```

# 8. Filter to those with highest fidelity (mean absolute percent error < 5%)

```{r high_fidelity}

hifiFacilities =  rsd.all %>% 
  # filter( mape <=.5 & abs( mpe ) < .1 ) %>%
  filter( abs( mpe ) < .1 ) %>%
  pull( orgUnit )

paste(
  'There are' , length( hifiFacilities ), 'facilities with data that closely fits the expected seasonal pattern.'
) 

```

# 9. Aggregate data by evaluation unit (e.g. district)

```{r AggHifiFacilitiesToDistrict}
newCols = c( 'stockoutsNew' , 'confCasesNew' , 'attendance'  )

dTs.district =
  
  dTs.36.new %>% 
  filter( orgUnit %in% hifiFacilities ) %>% 
  group_by( parentName ) %>% 
  summarise_at( newCols , sum , na.rm = TRUE ) %>% 
  as_tibble() %>%
  # add district level rain
  inner_join( dTs.36.new %>% as_tibble() %>%
                group_by( parentName , period ) %>% 
                summarise( rain = max( rain , na.rm = TRUE ) ) %>%
                mutate( rain_lag  = lag( rain )), 
              by = c( 'parentName', 'period')  ) %>%
  mutate( period = yearmonth( period ) ) %>%
  as_tsibble( key = parentName , index = period ) 
            
# glimpse( dTs.district)

FacilitiesPerDistrict = dTs.36.new %>% as_tibble() %>%
      filter( orgUnit %in% hifiFacilities ) %>%
      count( parentName , orgUnitName )

nFacilitiesPerDistrict = count( FacilitiesPerDistrict , parentName )

cat( 
  'For this analysis we are using "dTs.district" dataset, which is the aggregate of facilities,selected for highest quality in each district. There are an average of' , 
  round( mean( nFacilitiesPerDistrict$n ) ) , 
  'facilities per district (range:' , 
  paste( range( nFacilitiesPerDistrict$n ) , collapse = "-")  , ')'
)

nFacilitiesPerDistrict %>% arrange( - n )
  
```


# 10. Filter to pre-intervention period and split data into training and test sets

test data prior to Jan 2018.  Test data from Jan 2018 to Dec 2018.

```{r pre2019trainingData}

dTs.district.train = dTs.district %>% filter( period < yearmonth( "2018 Jan")) 

dTs.district.test = dTs.district %>% 
  filter( period >= yearmonth( "2018 Jan") & 
            period < yearmonth( "2019 Jan")) 

# recheck_for_gaps 
# has_gaps( dTs.district.train )

```

# 11. Specify models and run on training set (saved)

```{r fit.dTs.district.test , eval=FALSE }

fit.dTs.district.train = dTs.district.train  %>%
   # filter( parentName %in% 'Chiradzulu-DHO' ) %>% # for test ru: only 3 facilities
   filter( !is.na( rain ) ) %>%  # ensure there is rain data
   model(

          # ets = ETS( box_cox( confCasesNew , lambda = .5 ) ) ,

          # arima_log = ARIMA( box_cox( confCasesNew , lambda = .5 )  ~
          #                  pdq(0,1,1) + PDQ(0,1,0)) ,
 
          arima = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~
                           pdq(0:2,0:1,0:2) + PDQ(0:2,0:1,0:2) 
                           ) ,
# 
#           fourier1_log = ARIMA( confCasesNew ~
#                               fourier( K = 1 ) +
#                               pdq(0:1,0:1,0:1) + PDQ(0,0,0)
#                             ) ,

          rain = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~ 
                          rain  +
                          pdq(0:2,0:1,0:2) + PDQ(0:2,0:1,0:2) 
                        ) ,

          rain_lag = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~ 
                          rain_lag  +
                          pdq(0:2,0:1,0:2) + PDQ(0:2,0:1,0:2) 
                        ) ,
          
          rain_so = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~
                            rain +
                            stockoutsNew +
                          pdq(0:2,0:1,0:2) + PDQ(0:2,0:1,0:2) 
                        ) ,

          rain_lag_so = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~
                            rain_lag +
                            stockoutsNew +
                          pdq(0:2,0:1,0:2) + PDQ(0:2,0:1,0:2) 
                        ) 
          # 
          # rain_so_att = ARIMA(  confCasesNew  ~ 
          #                   rain +
          #                   stockoutsNew + 
          #                   attendance +
          #                 pdq(0:1,0:1,0:1) + PDQ(0:1,0:1,0:1) 
          #               ) 
   )

saveRDS( fit.dTs.district.train , 'MalawiPBO/fit.dTs.district.train.rds' )
```

Model formulas

```{r modelFormulas.district}

fit.dTs.district.train = readRDS('MalawiPBO/fit.dTs.district.train.rds' )

fit.dTs.district.train$rain_lag


```

```{r leaveOneOut_model_fit }


 fit.dTs.district.train.accuracy =
  fit.dTs.district.train %>% 
  accuracy() %>% 
  select( parentName , .model , RMSE, MAPE, MASE ) %>%
  arrange( parentName , MASE ) 

# MAPE Ranks
fit.dTs.district.train.accuracy %>% 
  group_by( parentName ) %>%
  arrange( parentName , MAPE ) %>%
  mutate( rank = row_number() ) %>% 
  ggplot() + 
  geom_line( aes(x = .model , y = rank , group = parentName ) ) +
  facet_wrap( ~parentName ) + 
  labs( title = 'Relative ranks of model fit' , 
        subtitle =  "1 is best; 5 is worst" 
  )

```

```{r model_metric_comparison}

map( 
  syms( c('RMSE', 'MAPE', 'MASE' ) ) , 
  ~ fit.dTs.district.train.accuracy %>% 
  group_by( parentName ) %>%
  arrange( parentName , !! .x ) %>%
  mutate( rank = row_number() ) %>%
  ggplot() + geom_histogram( aes( rank ) ,  ) +
  facet_wrap(~.model ) + 
    labs( title = 'Ranks of Model Fit' , subtitle = .x ) 
)

map( 
  syms( c('RMSE', 'MAPE', 'MASE' )) , 
  ~ fit.dTs.district.train.accuracy %>% 
  group_by( parentName ) %>%
  arrange( parentName , !! .x ) %>%
  ggplot() + 
    geom_violin( aes(x = .model , y = !! .x ) , na.rm = TRUE ) +
  # facet_wrap(~.model ) + 
    labs( title = 'Indicators of Model Fit' , subtitle = .x ) 
)

```

# 12. Cross-validate to check model fit 

Predict values in test period and compare predicted vs actual as mean absolute percent error (MAPE)

```{r cross_validate_dTs.district.train }

pred.dTs.district.train = fit.dTs.district.train %>%
  # select( - rain_so_att ) %>%  # \this model throws Error in as.matrix(newxreg) %*% coefs[-(1L:narma)] : non-conformable arguments
  forecast( new_data = dTs.district.test %>% 
              filter( !is.na( rain ) ) ) %>%
  group_by( .model ) %>%
  mutate( h = row_number() ) %>%
  ungroup()

# Whith too many diricts * models, this chart too busy!
# pred.dTs.district.train %>% 
#   autoplot( level = NULL ) + 
#   autolayer( dTs.district , confCasesNew ) 

pred.dTs.district.train.accuracy = accuracy( pred.dTs.district.train, dTs.district.test )

```


```{r crossValPlots}

map( 
  c("arima" , "rain" , "rain_so" , "rain_lag", "rain_lag_so" ) ,

     ~pred.dTs.district.train %>% 
       filter( .model %in% .x ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
       autolayer( dTs.district %>% filter( period < yearmonth( "2019 Jan") ) ,
                  confCasesNew , 
                  color = 'black' , alpha = .5 ) +
       facet_wrap( ~parentName , scale = 'free' ) +
       ggtitle( .x ) + guides( color = FALSE )
)

```

```{r}

pred.dTs.district.train %>% 
       filter( .model %in% 'rain_so', 
               parentName %in% "Lilongwe-DHO" ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
       autolayer( dTs.district %>% 
                    filter( period < yearmonth( "2019 Jan") ,
                            parentName %in% "Lilongwe-DHO" ) ,
                  confCasesNew , 
                  color = 'black' , alpha = .5 ) +
       # facet_wrap( ~parentName , scale = 'free' ) +
       ggtitle( '' ) + guides( color = FALSE )

```


# 12a. Calculate: Difference between actual and counterfactual in Pre-Invtervention period

```{r PreIntervention.difference}
# this is hard wired for the re-aggregated district data, dTs.district, and thte 
# district-level predictions, pred.dTs.district.postIntervention 

# accessory functions
mape <- function(actual,pred){
           mape <- mean(abs((actual - pred)/actual), 
                        na.rm = TRUE )*100
           return (mape)
}

mpe <- function(actual,pred){
            pctActual = ifelse( pred == 0 , NA ,
                                (actual - pred)/pred
                                )
           mpe <- mean( pctActual  , 
                        na.rm = TRUE )*100
           return (mpe)
}



district.PreIntervetnionDifference =  
  
  left_join( pred.dTs.district.train %>% as_tibble %>%
             rename( predicted = confCasesNew , district = parentName ) ,
             
             dTs.district.train %>% as.tibble %>%
               rename( actual = confCasesNew , district = parentName ) %>%
               select( district , period, actual ) , 
             
             by = c("district", "period")
             ) %>%
    mutate( difference = actual - predicted ) %>%
    group_by( district ) %>%
    summarise( percentChange = mpe( actual , predicted ) )


summary( district.PreIntervetnionDifference$percentChange )

# district.difference %>% arrange( percentChange ) %>% head(50)

cat(
  'For 2019, during the intervention period, the mean percent change from expected (by district) was' ,
  mean( district.PreIntervetnionDifference$percentChange , na.rm = TRUE  ) %>% round  ,
  '(range:' , 
  paste0( 
    range(district.PreIntervetnionDifference$percentChange , na.rm = TRUE) %>% round , 
    collapse = ' to ' 
    ) ,
  ')'
)
```

```{r chart.percentChangeDuringPreIntervention}


ggplot( district.PreIntervetnionDifference %>% filter( !is.na( percentChange )) ) + 
  geom_col( aes( y = reorder( district , -percentChange ) , 
                              x = percentChange ) ) + 
  labs( title = 'Percent change in number of confirmed malaria cases' ,
        subtitle = 'Cumulative change at selected facilities within district\nduring intervention period, Jan-Dec, 2019' ,
        y = 'District' , x = 'Percent Change'
        ) +
  scale_x_continuous( breaks = seq(-100, 200, 25))
 
```


# 13.  Select best model 

Due to missing values for rain, 3 districts not evaluated: Likoma, Mazimba-North, and Mazimba-South.  For the remaining districts, review of prediction suggests the rain-so model (covariates for rain and stockouts), the best fit

## 13a. Pre-intervention change: Actual number of cases in 2018 versus predicted


## 13b.  Estimate minimum change detectable (MPE)


```{r PRE.intervention.difference}

# accessory functions
mape <- function(actual,pred){
           mape <- mean(abs((actual - pred)/actual), 
                        na.rm = TRUE )*100
           return (mape)
}

mpe <- function(actual,pred){
            pctActual = ifelse( pred == 0 , NA ,
                                (actual - pred)/pred
                                )
           mpe <- mean( pctActual  , 
                        na.rm = TRUE )*100
           return (mpe)
}

PRE.district.difference =  
  
  left_join( pred.dTs.district.train %>% as.tibble %>%
               filter( .model %in% 'rain_so' ) %>% 
               rename( predicted = confCasesNew , district = parentName ) ,
             
             dTs.district %>% as.tibble %>% 
               rename( actual = confCasesNew , district = parentName ) %>%
               select( district , period, actual ) , 
             
             by = c("district", "period")
             ) %>%
    mutate( difference = actual - predicted ) %>%
    group_by( district ) %>%
    summarise( percentChange = mpe( actual , predicted ) )


summary( PRE.district.difference$percentChange )

# district.difference %>% arrange( percentChange ) %>% head(50)

ggplot( PRE.district.difference %>% filter( !is.na( percentChange )) ) + 
  geom_col( aes( y = reorder( district , -percentChange ) , 
                              x = percentChange ) ) + 
  labs( title = 'Percent change in number of confirmed malaria cases' ,
        subtitle = 'Cumulative change at selected facilities within district\nduring intervention period, Jan-Dec, 2018' ,
        y = 'District' , x = 'Percent Change'
        ) +
  scale_x_continuous( breaks = seq(-100, 200, 25))
  
cat(
  'For 2018, the mean percent change from expected (by district) was' ,
  mean( PRE.district.difference$percentChange , na.rm = TRUE  ) %>% round  ,
  '(range:' , 
  paste0( 
    range(PRE.district.difference$percentChange , na.rm = TRUE) %>% round , 
    collapse = ' to ' 
    ) ,
  ')'
)
```


# 14. Create new training set up to intervention period

```{r preInterventiontrainingData}

dTs.district.preIntervention = dTs.district %>% filter( period < yearmonth( "2018 Nov"))

dTs.district.intervention = dTs.district %>% 
  filter( period >= yearmonth( "2018 Nov") & period < yearmonth( "2020 Jan"))

# recheck_for_gaps 
# has_gaps( dTs.district.train )

```

# 15. Re-run model

```{r fit.dTs.district.preIntervention}

fit.dTs.district.preIntervention = dTs.district.preIntervention  %>%
   filter( !is.na( rain ) ) %>%  # ensure there is rain data
   model(
          
          rain_so = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~ 
                            rain +
                            stockoutsNew + 
                          pdq(0:1,0:1,0:1) + PDQ(0:1,0:1,0:1) 
                        ) 
   )


saveRDS( fit.dTs.district.preIntervention , 
      file = 'fit.dTs.district.preIntervention.rds'
)

```

```{r loadsSavedPred.dTs.district}

fit.dTs.district.preIntervention = readRDS(  
  'fit.dTs.district.preIntervention.rds' )

```



# 16. Predict values in test period and compare predicted vs actual as mean percent error (MPE)


```{r pred.dTs.district }

pred.dTs.district.postIntervention = 
  
  fit.dTs.district.preIntervention %>%
  forecast( new_data = dTs.district.intervention %>% 
              filter( !is.na( rain ) ) 
            ) 

```

```{r chartPostIntervention}

pred.dTs.district.postIntervention %>% 
       autoplot( color = 'red' , alpha = .5 ) + 
       autolayer( dTs.district %>% filter( period < yearmonth( "2020 Jan") ) ,
                  confCasesNew ,
                  color = 'black' , alpha = .5 ) +
       facet_wrap( ~parentName , scale = 'free' ) +
       ggtitle( 'Expected and Actual Cases, pre and post-intervention'  ) 

```
```{r ExamplePrePost}

example = dTs.district %>%  
  filter( parentName %in% "Lilongwe-DHO" ) 

e1 = example %>%  
  filter( period < yearmonth( "2018 Jan") ) %>% 
  autoplot( confCasesNew ) +
  expand_limits( x = yearmonth( "2020 Jan")) +
  labs( title = "Lilongwe Confirmed Cases" , 
        y = "Cases" , x = "Month") +
  theme_bw( base_size = 20 )

e2 = pred.dTs.district.train %>% 
       filter( .model %in% 'rain_so', 
               parentName %in% "Lilongwe-DHO" ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
  autolayer( example %>% 
               filter( period < yearmonth( "2018 Jan") ) ,
             confCasesNew ) +
  expand_limits( x = yearmonth( "2020 Jan")) +
  labs( title = "Lilongwe Confirmed Cases" , 
        y = "Cases" , x = "Month") +
  theme_bw( base_size = 20 )

e3 = pred.dTs.district.train %>% 
       filter( .model %in% 'rain_so', 
               parentName %in% "Lilongwe-DHO" ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
  autolayer( example %>% 
               filter( period < yearmonth( "2019 Jan") ) ,
             confCasesNew ) +
  expand_limits( x = yearmonth( "2020 Jan")) +
  labs( title = "Lilongwe Confirmed Cases" , 
        y = "Cases" , x = "Month") +
  theme_bw( base_size = 20 )

e4 = pred.dTs.district.postIntervention %>% 
       filter( .model %in% 'rain_so', 
               parentName %in% "Lilongwe-DHO" ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
  autolayer( example %>% 
               filter( period < yearmonth( "2019 Jan") ) ,
             confCasesNew ) +
  expand_limits( x = yearmonth( "2020 Jan")) +
  labs( title = "Lilongwe Confirmed Cases" , 
        y = "Cases" , x = "Month") +
  theme_bw( base_size = 20 )

e5 = pred.dTs.district.postIntervention %>% 
       filter( .model %in% 'rain_so', 
               parentName %in% "Lilongwe-DHO" ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
  autolayer( example %>% 
               filter( period < yearmonth( "2020 Jan") ) ,
             confCasesNew ) +
  expand_limits( x = yearmonth( "2020 Jan")) +
  labs( title = "Lilongwe Confirmed Cases" , 
        y = "Cases" , x = "Month") +
  theme_bw( base_size = 20 )

ggsave("MalawiPBO/e1.png" , e1 , width = 10 , height = 5.5 ) 
ggsave("MalawiPBO/e2.png" , e2 , width = 10 , height = 5.5 ) 
ggsave("MalawiPBO/e3.png" , e3 , width = 10 , height = 5.5 ) 
ggsave("MalawiPBO/e4.png" , e4 , width = 10 , height = 5.5 ) 
ggsave("MalawiPBO/e5.png" , e5 , width = 10 , height = 5.5 ) 

```

# 17. Calculate: Difference between actual and counterfactual 

```{r intervention.difference}
# this is hard wired for the re-aggregated district data, dTs.district, and thte 
# district-level predictions, pred.dTs.district.postIntervention 

# accessory functions
mape <- function(actual,pred){
           mape <- mean(abs((actual - pred)/actual), 
                        na.rm = TRUE )*100
           return (mape)
}

mpe <- function(actual,pred){
            pctActual = ifelse( pred == 0 , NA ,
                                (actual - pred)/pred
                                )
           mpe <- mean( pctActual  , 
                        na.rm = TRUE )*100
           return (mpe)
}



district.difference =  
  
  left_join( pred.dTs.district.postIntervention %>% as.tibble %>%
             rename( predicted = confCasesNew , district = parentName ) ,
             
             dTs.district %>% as.tibble %>%
               rename( actual = confCasesNew , district = parentName ) %>%
               select( district , period, actual ) , 
             
             by = c("district", "period")
             ) %>%
    mutate( difference = actual - predicted ) %>%
    group_by( district ) %>%
    summarise( percentChange = mpe( actual , predicted ) )


summary( district.difference$percentChange )

# district.difference %>% arrange( percentChange ) %>% head(50)

cat(
  'For 2019, during the intervention period, the mean percent change from expected (by district) was' ,
  mean( district.difference$percentChange , na.rm = TRUE  ) %>% round  ,
  '(range:' , 
  paste0( 
    range(district.difference$percentChange , na.rm = TRUE) %>% round , 
    collapse = ' to ' 
    ) ,
  ')'
)
```

```{r chart.percentChangeDuringIntervention}


ggplot( district.difference %>% filter( !is.na( percentChange )) ) + 
  geom_col( aes( y = reorder( district , -percentChange ) , 
                              x = percentChange ) ) + 
  labs( title = 'Percent change in number of confirmed malaria cases' ,
        subtitle = 'Cumulative change at selected facilities within district\nduring intervention period, Jan-Dec, 2019' ,
        y = 'District' , x = 'Percent Change'
        ) +
  scale_x_continuous( breaks = seq(-100, 200, 25))
 
```


# 17. Evalutate impact  

Match intervention to district.

```{r matchIntervention}

intervention = 
  read_excel( 'MalawiPBO/PBO Monitoring in Malawi_last updated Nov 2018.xlsx' , sheet = 'Districts List') %>%
  rename( districtName = `Region/ District Name` , net = `Type of nets/Intervention` ,
          campaign = `Dates of mass campaign` ) %>%
  filter( ! is.na( net )) %>%
  mutate( 
    district = paste0( districtName , '-DHO' ) 
    ) %>%
  mutate(
    district = 
      case_when( 
        district == "Nkhata Bay-DHO" ~ "Nkhata-Bay-DHO" ,
        district == "Mzimba South-DHO" ~ "Mzimba-South-DHO" ,
        district == "Mzimba North-DHO" ~ "Mzimba-North-DHO" ,
        TRUE ~ district 
      ))

```

List of district names that may not have matched...

```{r unmatchedDistricNames}


# find districts names that don't match dhis2
dhisDistrictNames = unique( district.difference$district )

# setdiff( intervention$district , dhisDistrictNames )

district.difference.Intervention = 
  left_join(
    district.difference ,
    intervention , by = 'district' 
    ) 

```


```{r chart.Intervention}

ggplot( district.difference.Intervention %>% filter( !is.na( percentChange )) ) + 
  geom_col( aes( y = reorder( district , -percentChange ) , 
                 x = percentChange ,
                 fill = net )
            ) + 
    labs( title = 'Percent Difference: Expected minus actual confirmed malaria cases' ,
        subtitle = paste( 
          'Cumulative differnce at selected districts* ( n=' ,
          nrow( district.difference.Intervention %>% 
                  filter( !is.na( percentChange ))) ,
          ') during\nintervention period, Jan-Dec, 2019' 
          ) ,
        caption = '*precipitation data temporarily not available for 3 districts' ,
        y = 'District' , x = 'Percent Change'
        ) +
  scale_x_continuous( breaks = seq(-100, 200, 25))
 
```

## 17.a calculate MPE by intervention,  

Estimate the mean difference, and estimate the likelihood that difference > 0
Mean (and standard error of mean) of percent change:

```{r mean_differences }


stderr <- function(x, na.rm=TRUE ) {
  if (na.rm) x <- na.omit(x)
  sqrt(var(x)/length(x))
}

district.difference.Intervention %>% group_by( net ) %>%
  summarise( Mean = mean( percentChange , na.rm = TRUE ) ,
             SE =  stderr( percentChange )
               )
 

```

## 17.a perform some statistical test of the percentChange by intervention

rank-sum test :

Review of concept behind Rank-sum test  [here](http://www.r-tutor.com/elementary-statistics/non-parametric-methods/mann-whitney-wilcoxon-test).  

- exclude districts with IRS mixed standard/PBO nets.

```{r district.rankSum}
dd = district.difference.Intervention  %>%  
  filter( grepl("^PBO$|^Standard$", net) )

wilcox.test(  percentChange ~ net  , data = dd  ) 
```

t-test 

```{r t.test}
district.pbo = dd %>% filter( net %in% 'PBO' ) %>% pull( percentChange )
district.standard = dd %>% filter( net %in% 'Standard' ) %>% pull( percentChange )

t.test( district.pbo, district.standard )
```

- [Bayesian version of t.test](https://github.com/rasmusab/bayesian_first_aid)

```{r bayes.t.test}
# devtools::install_github("rasmusab/bayesian_first_aid")
library( BayesianFirstAid )
district.btt = bayes.t.test( district.pbo, district.standard )
plot(district.btt)
```



# 18 To strengthen association with intervention, 

A. look at change when including more facilities in district aggregate.  

B. Compare individual facilities rather district.  What is the range of change within each district?  What is the mean change by facility with/without intervention.

- create datasets 

```{r dTs.hifi.preIntervention}

  dTs.hifi = dTs.36.new %>% 
  filter( orgUnit %in% hifiFacilities , 
          !is.na( rain ) ,
          ) 

  dTs.hifi.preIntervention = dTs.hifi %>%
  filter( period < yearmonth( "2018 Nov"))

  dTs.hifi.intervention = dTs.hifi %>% 
    filter( period >= yearmonth( "2018 Nov") & period < yearmonth( "2020 Jan")) %>%
    fill_gaps()


```

- run arima model with rain and stockout covariates (saved)

```{r fit.dTs.hifi.preIntervention , eval=FALSE }

 fit.dTs.hifi.preIntervention = dTs.hifi.preIntervention  %>%
  fill_gaps() %>%

   model(
          
          rain_so = ARIMA( box_cox( confCasesNew , lambda = .5 ) ~ 
                            rain +
                            stockoutsNew + 
                          pdq(0:2,0:1,0:2) + PDQ(0:2,0:1,0:2) 
                        ) 
   ) 

saveRDS( fit.dTs.hifi.preIntervention ,
      file = 'MalawiPBO/fit.dTs.hifi.preIntervention.rds'
)


```

- predict counterfactual

```{r pred.dTs.hifi }

fit.dTs.hifi.preIntervention = readRDS( 'MalawiPBO/fit.dTs.hifi.preIntervention.rds' )

  
pred.dTs.hifi.postIntervention =  fit.dTs.hifi.preIntervention %>%
  forecast( new_data = dTs.hifi.intervention ) 

```

- calculate difference between counterfactual and actual 

```{r hifi.intervention.difference}
# this is hard wired for the re-aggregated district data, dTs.district, and thte 
# district-level predictions, pred.dTs.district.postIntervention 

# accessory functions
mape <- function(actual,pred){
           mape <- mean(abs((actual - pred)/actual), 
                        na.rm = TRUE )*100
           return (mape)
}

mpe <- function(actual,pred){
            pctActual = ifelse( pred == 0 , NA ,
                                (actual - pred)/pred
                                )
           mpe <- mean( pctActual  , 
                        na.rm = TRUE )*100
           return (mpe)
}


hifi.difference =  
  
  left_join( pred.dTs.hifi.postIntervention %>% as_tibble %>%
             rename( predicted = confCasesNew , district = parentName ) ,
             
             dTs.hifi %>% as.tibble %>%
               rename( actual = confCasesNew , district = parentName ) %>%
               select( orgUnit , period, actual ) , 
             
             by = c("orgUnit", "period")
             ) %>%
    mutate( difference = actual - predicted ) %>%
    group_by( district, orgUnit ) %>%
    summarise( percentChange = mpe( actual , predicted ) )


summary( hifi.difference$percentChange )

# district.difference %>% arrange( percentChange ) %>% head(50)

cat(
  'For 2019, during the intervention period, the mean percent change from expected (by district) was' ,
  mean( hifi.difference$percentChange , na.rm = TRUE  ) %>% round  ,
  '(range:' , 
  paste0( 
    range(hifi.difference$percentChange , na.rm = TRUE) %>% round , 
    collapse = ' to ' 
    ) ,
  ')'
)
```

```{r}

pred.dTs.hifi.postIntervention %>% 
       filter( .model %in% 'rain_so', 
               orgUnitName %in% "Daeyang Luke Hospital" ) %>%  
       autoplot( color = 'red' , alpha = .5 ) + 
       autolayer( dTs.new %>% 
                    filter( period < yearmonth( "2019 Jan") ,
                            orgUnitName %in% "Daeyang Luke Hospital" ) ,
                  confCasesNew , 
                  color = 'black' , alpha = .5 ) +
       # facet_wrap( ~parentName , scale = 'free' ) +
       ggtitle( '' ) + guides( color = FALSE )

```

- Evaluate intervention

```{r hifi.intervention}

hifi.difference.Intervention = 
  left_join(
    hifi.difference ,
    intervention , by = 'district' 
    ) 


ggplot( hifi.difference.Intervention %>% filter( !is.na( percentChange )) ) + 
  geom_col( aes( y = reorder( orgUnit , -percentChange ) , 
                 x = percentChange ,
                 fill = net )
            ) + 
  labs( title = 'Percent Difference: Expected minus actual confirmed malaria cases' ,
        subtitle = paste( 
          'Cumulative differnce at selected facilities* ( n=' ,
          nrow( hifi.difference.Intervention) ,
          ') during\nintervention period, Jan-Dec, 2019' 
          ) ,
        caption = '*facilities were selected based on quality of historic data, without regard to intervention status.' ,
        y = 'Facility' , x = 'Percent Change'
        ) +
  scale_x_continuous( breaks = seq(-100, 200, 25)) +
  theme(axis.text.y=element_blank())

```

```{r hifi.mean_differences }


stderr <- function(x, na.rm=TRUE ) {
  if (na.rm) x <- na.omit(x)
  sqrt(var(x)/length(x))
}

hifi.difference.Intervention %>% group_by( net ) %>%
  summarise( Mean = mean( percentChange , na.rm = TRUE ) ,
             SE =  stderr( percentChange )
               )
 
saveRDS(hifi.difference.Intervention , 
        'MalawiPBO/hifi.difference.Intervention.rds' )

```


## 18.a perform some statistical test of the percentChange by intervention

rank-sum test :

Review of concept behind Rank-sum test  [here](http://www.r-tutor.com/elementary-statistics/non-parametric-methods/mann-whitney-wilcoxon-test).  

- exclude districts with IRS mixed standard/PBO nets.

```{r hifi.rankSum}
hifi.dd = hifi.difference.Intervention  %>%  
  filter( grepl("^PBO$|^Standard$", net) )

wilcox.test(  percentChange ~ net  , data = hifi.dd  ) 
```

t-test 

```{r hifi.t.test}
hifi.pbo = hifi.dd %>% filter( net %in% 'PBO' ) %>% pull( percentChange )
hifi.standard = hifi.dd %>% filter( net %in% 'Standard' ) %>% pull( percentChange )

t.test( hifi.pbo, hifi.standard )
```

- [Bayesian version of t.test](https://github.com/rasmusab/bayesian_first_aid)
```{r hifi.bayes.t.test}
# devtools::install_github("rasmusab/bayesian_first_aid")
library( BayesianFirstAid )
hifi.btt = bayes.t.test( hifi.pbo, hifi.standard )
plot(hifi.btt)
```


## 18.b Map of impact 

```{r mapDistrictImpact }

  hifi.difference.Intervention = readRDS(  
        'MalawiPBO/hifi.difference.Intervention.rds' )


  ous.sf = readRDS( '../dataDictionary/malawi_ous_sf.rds' )  %>%
    rename( orgUnit = id , orgUnitName = name ) %>%
    left_join( OrgUnitLevels %>% 
                 select( level, levelName ) ,
             by = 'level' )  
  
  d = right_join( hifi.difference.Intervention %>% 
                    ungroup %>%
                    select( orgUnit , percentChange, net ) , 
                  ous.sf %>% filter( level < 5),
                  by = 'orgUnit'
                  ) %>% 
    mutate( Decline = percentChange< 0 ,
            Change = abs( percentChange ))  %>% 
    st_as_sf %>%
    filter( ! is.na( net ) & level > 3)

  split_geofeatures = split( d , d$net )
    
  n_levels = length( split_geofeatures )

    
    colors = RColorBrewer::brewer.pal( n_levels, 'Accent')
    
    
    ggplot() +
      geom_sf(data = ous.sf %>% select(-parent) %>%
                filter( level == 3 ) ) +
      theme_minimal() +
      geom_sf(data = d , aes( color = net, fill = net ))
    

ggsave( 'MalawiPBO/map.png' )
```


```{r mapView}

    m = mapView( split_geofeatures , 
                 col.regions = as.list( colors ) 
                 ) +
      mapView( d , zcol = "Decline" , 
               cex = "Change"
               )
    
    m@map %>% leaflet::addCircleMarkers( 
      data = d %>% 
        filter( st_geometry_type(d) %in% 'POINT' ) , 
      color = 'Decline', radius = 'Change' 
      )
    
```

# 19.  Compare results with other methods:

  A. excel-based sum up district cases and compare without examining facility-level data
  
  B. 