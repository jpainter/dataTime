---
title: "Difference between DHIS2 'dataset reporting' rate and data reporting rate"
output: html_notebook
params:
  country: "Malawi"
  evaluation: 'Reporting'
  run_models: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( echo = FALSE, cache = TRUE, 
                       message = FALSE , warning = FALSE )
```

```{r packages, include= FALSE}

library(pacman)
p_load( officer , rvg ,tidyverse, scales, tidyfast, tidytable, 
        lubridate , anytime , progressr , 
        readxl, patchwork, cowplot, kableExtra ,
        tsibble, fable, fabletools, feasts, 
        fable.prophet ,  fable.bsts , 
        slider, anomalize, brolgar ,
        tsbox , CausalImpact , tibbletime , dygraphs , 
        fpp3  , fabletools, 
        furrr, tictoc, magrittr, hrbrthemes, data.tree, igraph ,
        sf, mapview, GGally , plotly , sugrrants
        )



# Functions
source( '../dataDictionary/TS_Modeling_Functions.r')
# source("Model_TS.R") # new version of model.ts()
source("Summary_TS.R") # new version of summary_ts()
source('TS_model_outlier_impute.R') # model_ts()
source( 'Deviation_Expected_Functions.R')
source( 'theme_ppt.R')
source( 'clean_ts.r' )

Month_Year = function( x ){ yearmonth( zoo::as.yearmon( x , "%Y%m") ) }

options(dplyr.summarise.inform = FALSE)

output.folder =  paste0( params$country, "/" , params$evaluation )

dir.create( file.path( getwd(), 
                      output.folder
                       ) , recursive = TRUE
)

country = params$country
indicator = params$evaluation 

plan( multisession  )

```

```{r helper_functions}

files = function(  search = 'All' , type = 'xlsx' , other = "" , ... ){
                        
                      dir = file.dir( ... )
                      dir.files = list.files( dir )
                      search_and_type =  
                          str_detect( dir.files, fixed( search , ignore_case=TRUE )  )  &
                           grepl( paste0( type , '$' ) , dir.files, 
                                  ignore.case =  TRUE  ) &
                          grepl( other , dir.files , ignore.case = TRUE ) 
                      files = dir.files[  search_and_type   ]
                      return( files[ rev( order( files )) ]  )
                      }

file.dir = function( country = params$country ,
                     dir.base = '../dataDictionary/dhis2_dictionary/Formulas/' ){
  paste0( dir.base , country , "/")
}

string_wrap = function(string, nwrap=20) {
  paste(strwrap(string, width=nwrap), collapse="\n")
}

string_wrap = Vectorize(string_wrap)


stderr <- function(x, na.rm=TRUE ) {
  if (na.rm) x <- na.omit(x)
  sqrt(var(x)/length(x))
}

```

```{r data_theme}

subject = c( 'stock' , 'cases' , 'attendance', 'malaria death', 
             'all-cause death'  )

country = params$country
  
data.files = map( subject ,
                      ~files( search = .x , country = country , other = "All Levels" )
)

# Find most recent file 
most_recent_file = function( file_list_with_date ){
  rdsFileSplit = str_split( file_list_with_date, "_")
  download_date = map( rdsFileSplit ,
      ~str_split( .x[ length(.x)] , "\\.")[[1]]
  ) %>% map_chr(1) 
  
  dates  = map_chr( download_date , ~ anydate(.x)  )
  
  # most recent file 
  file = file_list_with_date[ which( dates == max(dates, na.rm = T ) ) ]
  return ( file )
}

most_recent_data_files = map_chr( data.files , most_recent_file )

```

```{r data_requests}

data_requests = tribble( 
    ~name , ~file ,
    # 'districtRain' , '../ARC/malawi_arc.rds' ,
    subject[1] ,  most_recent_data_files[1] ,
    subject[2]  , most_recent_data_files[2] ,
    subject[3]  , most_recent_data_files[3] ,
    subject[4] , most_recent_data_files[4] ,
    subject[5] , most_recent_data_files[5] ,
    'metadata' , meta.file = files( 'meta' , country = country  )[1]
)

data_requests
    
```


```{r, s2}

s2 = function( data_requests , folder ){
    
    for ( i in 1:nrow( data_requests )){
        
        print( data_requests$file[i] )
        
        if ( grepl( '.xlsx' , data_requests$file[i] ) &
             !grepl( 'metadata' , data_requests$file[i] , ignore.case = TRUE ) 
             ){
            
            path = paste0( folder, data_requests$file[i] )
            name = data_requests$name[i]
            
            # summary data
            assign( name , read_excel( path , 'summaryData', 
                                       guess_max = 100000 )  %>%
                        filter( Count.Any != 0 )  %>%
                        mutate( !! name := as.integer( Total ) ) %>%
                        select( orgUnit, orgUnitName , period, !! name ) ,
                    envir = .GlobalEnv )
            
            # formula elements
            x = read_excel( path , 'formulaData')  %>%
                unite( 'de' , dataElement, Categories , remove = TRUE ) 
                       
            x.  = x %>% 
                mutate( SUM = as.integer( SUM ) ) %>%
                pivot_wider( id_cols = c(orgUnit , orgUnitName , period ), 
                                     names_from = de , 
                                     values_from = SUM
                                     )
            
            # if ( x$de %>% unique %>% length > 1 ){
            #     assign( paste0( name, 'x') , x. , envir = .GlobalEnv )
            # }
            
        }
        
        if ( grepl( 'metadata' , data_requests$file[i] , ignore.case = TRUE ) ){
            print( 'orgUnits and orgUnitLevels' )
            path = paste0( folder, data_requests$file[i] )
            assign( 'orgUnits' , read_excel( path , 'OrgUnits'  ) , 
                    envir = .GlobalEnv )
            assign( 'OrgUnitLevels' , read_excel( path , 'OrgUnitLevels'  ) , 
                    envir = .GlobalEnv )
        }
        
        if ( grepl( 'arc|rain' , data_requests$file[i] , ignore.case = TRUE ) ){
            
            path = data_requests$file[i] 
            name = data_requests$name[i]
            assign( name , readRDS( path ) ,
                    envir = .GlobalEnv )

        }
        
    }
}

```

```{r s2_create_datasets}

folder = paste0(
  '../dataDictionary/dhis2_dictionary/Formulas/' ,
  params$country , "/")

# create dataset objects in memory
# One data set for summary values and another with each element-category (suffix 'x').  e.g. confCases and confCasesx
s2( data_requests , folder )


# stockoutsx = stockoutsx %>%
#     mutate_at( vars( contains('stock') ) ,  ~ifelse(.x > 31 , NA, .x ) )

```

```{r combine_datasets }

dataset = base::get( subject[1]  ) 

for (i in 2:length( subject )){
  
  if ( exists( subject[i] ) ){
    x = base::get( subject[i]  ) 
    if ( !is_tibble( x ) ) return()
    dataset = full_join( dataset , x ,
                         by = c( 'orgUnit' , 'orgUnitName' , 'period' ) )
  }
}

# Get parent (district) name
parent =  left_join( orgUnits %>% select(levelName, id, parent)  ,
                     orgUnits %>% select( id, name) %>% rename( parentName = name ) ,
                     by = c('parent' = 'id' ) 
) %>%
    left_join( orgUnits %>% select(levelName, id ) %>% rename(parentLevel = levelName ) , 
               by = c('parent' = 'id' ) 
               )


d = left_join( dataset , parent %>% select( id, parent , parentName ) , 
                     by = c('orgUnit' = 'id' )) %>%
    mutate( period = zoo::as.yearmon( period, "%Y%m") %>%
                    yearmonth( . )  ) %>%
  
    # remove stockout day values >31
    mutate_at( vars( contains('stock') ) ,  ~ifelse(.x > 31 , NA, .x ) ) 

if ( "districtRain" %in% data_requests$name ){
    d = d %>% 
      left_join( districtRain %>% 
                 as_tibble() %>%
                 select( month , orgUnit , avg_month ) %>%
                 rename( rain = avg_month ) %>%
                 arrange(orgUnit, month ) %>% 
                 mutate( rain_lag = lag( rain , n=1) ) , 
               by = c( 'parent' = 'orgUnit' , 'period' = 'month' ) )
}
# Remove column with missing data , NA_NA
if ( any( grepl( 'NA_NA' , names(d) ) ) ) d = d %>% select( -starts_with( 'NA_NA' ) )

# glimpse( d )
# View( d )
```

# 2.b Identify 'leaf' facilitieso

## 2.b OUS structure

```{r}

meta.file = data_requests %>% filter(name == 'metadata') %>%
  pull(file)

ous = read_excel( paste0( folder,  meta.file ) , sheet = 'OrgUnits')
ous.levels = read_excel( paste0( folder,  meta.file ) , sheet = 'OrgUnitLevels')

ous.id_parent = ous %>% select( id, parent )
ous.id_parent[ is.na( ous.id_parent$parent) , 'parent'] = params$country
ous.tree = FromDataFrameNetwork( ous.id_parent )

ou_leaves = ous.tree$Get("isLeaf")
ous.leaves = tibble( id = attributes(ou_leaves)$name , 
                      tree.leaf = ou_leaves ) %>%
             inner_join( ous , by = 'id')

# count( ous.leaves , leaf, tree.leaf ) %>%
#   kbl() %>%
#   kable_styling()

count( ous.leaves, level , levelName , tree.leaf ) %>% 
  pivot_wider( names_from = tree.leaf , values_from = n ) %>%
  arrange( level ) %>%
  kbl() %>%
  kable_styling()

district = ous.leaves %>%
  filter( levelName %in% 'District' , ! tree.leaf ) %>%
  select( id, name ) %>%
  rename( orgUnit = id, district = name )
  
```

In DHIS2, umbrella admin units like District, or Region, sum up the data from orgUnits beneath them. But sometimes there are district hospitals that report data directly at District level. And, In some countries, CHW or other units, are listed under a facility. As a result, the facility is not the leaf. However, many of these units under the facility do not report data. Therefore, need to look at the data itself to figure out which facilities are reporting data and which are admin structures that simply add up the data under them.

```{r}

district = filter( district, grepl('DHO', district ) )

```

## 2.b data.tree

```{r }

ous.parent.child = d %>% 
  select( orgUnit ) %>%
  distinct( orgUnit) %>%
  inner_join( ous %>% select( id, parent ) , by = c( 'orgUnit' = 'id') ) %>%
  filter( !is.na( parent ))

data.tree <- FromDataFrameNetwork( ous.parent.child )

# data.tree = FromDataFrameNetwork( 
#   ous %>% select( id, parent ) %>% filter( !is.na( parent ) ) 
#           )

```


<!-- Loading saved data.leaves currently turned off by default. -->

<!-- ```{r, eval=TRUE } -->
<!-- dir = file.dir( params$country ) -->
<!-- paths = readRDS( paste0( dir, 'ou_paths.rds') ) -->
<!-- data.leaves = readRDS( paste0( dir, 'data.leaves.rds') ) -->

<!-- ``` -->

## 2.b data.leaves

```{r}


data.leaves = data.tree$Get("isLeaf")
data.leaves = tibble( id = attributes(data.leaves)$name , 
                      effectiveLeaf = data.leaves )

```


## 2.b link data with hierarchy

```{r}

data = d %>%
  left_join( ous %>% select( id, leaf, level, levelName), 
             by = c( 'orgUnit' = 'id') ) %>%
  left_join( data.leaves , by = c( 'orgUnit' = 'id') ) 
 
# count( data ,  effectiveLeaf ) %>%
#   kbl() %>%
#   kable_styling()

count( data %>% 
         group_by( level , levelName, orgUnit ) %>% 
         summarise( effectiveLeaf = unique( effectiveLeaf ) ) , 
       level , levelName , effectiveLeaf ) %>% 
pivot_wider( names_from = effectiveLeaf , values_from = n ) %>%
arrange( level ) %>%
  kbl() %>%
  kable_paper("hover", full_width = F)


```

## 2.b prepare leaf datasets (d) as time-series (effectiveLeaf)

```{r}

  d = data  %>%
    filter( effectiveLeaf == TRUE  )

  # rm( ous.parent.child , data.leaves, data.tree, ous.tree  ); gc()

 keyCols = c( 'orgUnit', 'orgUnitName', 'parent', 'parentName', 'level', 'levelName' , 'leaf' , 'effectiveLeaf'  ) 
```

# 3. Convert data to time-series

```{r cols}

dataCols = setdiff( names( d ), c( keyCols , 'period', 'geometry', 'leaf', 'level' , 'levelName', 'effectiveLeaf' ) )

```

```{r data_set_to_ts}

dTs = d %>% 
    as_tsibble( index =  period, 
                        key = {{ keyCols }} 
                        )  %>% 
    pivot_longer( {{ dataCols }} ,
                  values_to = 'original' ,
                  names_to = 'vars' )
    # index_by( year_month = yearmonth( month ) ) %>%

if ( sum( has_gaps( dTs )$.gaps ) > 0 )  dTs = fill_gaps( dTs)

# measures( dTs )
# interval( dTs )

```

# 3.1  Testing, Validation, and Evaluation periods

```{r}

study_end = ( as.Date(max( dTs$period )) - months(2) ) %>% yearmonth

study_start = ( as.Date( study_end ) - years(4) ) %>% yearmonth

evaluation_start = study_start

evaluation_end = study_end

evaluation_period = as.Date( evaluation_start:evaluation_end ) %>% 
  yearmonth %>% unique()

validation_start = evaluation_start - month(12)

# validation ~ 12 months prior to intervention 
validation_period = evaluation_start - month(12):month(1)


study_period = as.Date( 
  study_start:evaluation_end
  ) %>% 
  yearmonth %>% unique()
  
testing_period = as.Date( 
  study_start:( validation_start - month(1) ) 
  ) %>% 
  yearmonth %>% unique()

training_period = as.Date( 
  study_start:( evaluation_start - month(1) )
  ) %>% 
  yearmonth %>% unique()

vali_eval_period =  c(validation_period , evaluation_period ) 




```


```{r}

testing  = function(x) x %>%
  filter( period < validation_start ,
          vars %in% data_cols )

validation  = function(x) x  %>%
  filter( period %in%  validation_period ,
           vars %in% data_cols )

training = function(x) x  %>% 
  filter( period < evaluation_start ,
           vars %in% data_cols )

evaluation = function(x) x  %>% 
  filter( period %in% evaluation_period ,
           vars %in% data_cols )

```
 
## 3.2 Original data

```{r}

  reporting_through = max( dTs$period ) 
  reporting_as_of = min( dTs$period ) 
  reporting_months = length( dTs$period %>% unique  ) 
    
  dTs %>%  
    group_by( vars ) %>%
    summarise( original = sum( original, na.rm = TRUE ) ) %>% 


    autoplot( original ) +
    facet_wrap( ~ vars , scale = 'free' ,
                labeller = labeller( vars = label_wrap_gen(50)) 
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'Total'  , 
          x = ''  ,
          title = 'Original Data Totals' ,
          subtitle = paste( 'From' , reporting_as_of , 'through' , 
                            reporting_through , "(" ,
                            reporting_months , " months )")  )

```


## 3.3 Crude (unadjusted) Impact Evaluation

# 4. Calculate data counts

```{r nonMissing_chart2, eval=TRUE }

data_histogram = function( data , .period , element = 'original' , cols = NA  ){

  element = sym( element )
  
  reporting_through = max( .period ) 
  reporting_as_of = min( .period ) 
  reporting_months = length( .period ) 

  d = data %>% as_tibble 

  if ( any( !is.na( cols ) ) ) d = d %>% filter( vars %in% cols )
    
    
  d %>%  
    
    filter( period %in% .period ) %>%

    group_by( orgUnit , vars ) %>%
    summarise( Months_with_Data = sum(!is.na( {{ element }})) ) %>% 
    group_by( orgUnit, vars ) %>%
    summarise( Months_with_Data = max( Months_with_Data )  ) %>% 
    
    ggplot() + 
    geom_histogram( aes( x = Months_with_Data ) , binwidth = 1 ) +
    facet_wrap( ~ vars ,
                labeller = labeller( vars = label_wrap_gen(50)) 
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = 'Months with Data'  ,
          title = 'Months of Data Available' ,
          subtitle = paste( 'From' , reporting_as_of , 'through' , 
                            reporting_through , "(" ,
                            reporting_months , " months )") ,
          caption = paste( 'Data:' , deparse(substitute( data )) , 
                           "(" , element , ")"))

}

data_histogram( dTs, study_period )



```

## 4a. Compare counts with form submissions

```{r}

reporting = readRDS( paste0( folder , params$country , '_0_Reporting_National.rds' )  )
  
d.n = reporting %>% 
          mutate( period = zoo::as.yearmon( period, "%Y%m") %>%
                    yearmonth( . )  ,
                  value = as.integer( value )
          ) 
# %>%
#   filter( period %in% study_period )

ggplot( d.n %>%  filter( dataSet %in% 'HMIS 15' ) , 
        aes( x = period ,  y = value, group = reporting, color = reporting ) ) +
  geom_line() +
  facet_wrap( ~dataSet , scales = 'free' ,
              labeller = labeller( dataSet = label_wrap_gen(50))
              ) +
  labs( title ='National reporting', x = '' , y = '' ) +
  scale_color_ipsum() +
  labs( title ='National reporting')
```

```{r}

confCasesOrgUnits = dTs %>% filter( vars %in% 'cases' ) %>% 
  .$orgUnit %>% unique()

reportingOrgUnits = reporting %>% filter( dataSet %in% 'HMIS 15' ,
                                          reporting %in% 'ACTUAL_REPORTS' ) %>% 
  .$value %>% max(na.rm = T ) %>% as.integer()

expectedOrgUnits = reporting %>% filter( dataSet %in% 'HMIS 15' ,
                                          reporting %in% 'EXPECTED_REPORTS' ) %>% 
  .$value %>% max(na.rm = T ) %>% as.integer()

cat( 'Over several years,' , length( confCasesOrgUnits ), ' orgunits reported malaria case data, and up to ',
     reportingOrgUnits , 'of' , expectedOrgUnits
     , 'orgunits that submitted a dataset in any one month ' )

# dTs %>% filter( vars %in% 'confCases' ) %>% as_tibble() %>%
#   group_by( period ) %>%
#   summarise( n = n() ) %>%
#   arrange( desc( n ) ) %>%
#   filter( row_number() == 1 )

```

```{r}

# link dTs with report forms.  

# routine_data_files = data_requests$file[ !grepl( 'arc|metaData'  , data_requests$file ) ]
# 
# dsets[ 1:length( routine_data_files ) ] = list( NA )
# 
# for ( i in seq_along( routine_data_files ) ){
#   
#   dsets[[ i ]] = read_excel( paste0( folder , routine_data_files[i] ) , "Formula Elements") %>% 
#     filter( dataSet.id != "NA" ) %>% 
#     select( dataSet.id , dataSet , dataElement  ) %>%
#     unique
#   
# }
# 
# dset = bind_rows( dsets )
chart_data = dTs %>% 
  filter( period %in%  study_period )

  reporting_through = max( chart_data$period ) 
  reporting_as_of = min( chart_data$period ) 
  reporting_months = length( unique( chart_data$period )  )

chart_data %>% 
    group_by( vars ) %>%
    summarise( n = sum(!is.na( original )) ) %>% 

    ggplot() + 
    geom_line( aes( x = period , y = n )  ) +
    facet_wrap( ~ vars ,
                labeller = labeller( vars = label_wrap_gen(50))
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = ''  ,
          title = 'Data Reporting During Study Period' ,
          subtitle = paste( 'From' , reporting_as_of , 'through' , 
                            reporting_through, "(" ,
                            reporting_months , " months )") )


```

```{r}

chart_data %>% 
    # left_join( dset )
    # filter to more recent range 
    # filter( period %in%  study_period ) %>%
    pivot_wider( values_from = original , names_from = vars ) %>%
    mutate( nonMalaria_Attendance = attendance - cases ) %>%
    pivot_longer( cols = c( {{ dataCols }} , nonMalaria_Attendance ) , 
                  names_to = 'vars' , values_to = 'original' ) %>%
    group_by( vars ) %>%
    summarise( total = sum( original, na.rm = TRUE ) ) %>% 

    ggplot() + 
    geom_line( aes( x = period , y = total )  ) +
    facet_wrap( ~ vars , scales = 'free' ,
                labeller = labeller( vars = label_wrap_gen(50))
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = ''  ,
          title = 'Reported Totals' ,
          subtitle = 'unadjusted, reported "as is"'  )


```

# Select consistent reporters

```{r}

maxInterval = dTs %>% 
  filter( period %in% study_period ) %>%
  as_tibble %>%
  group_by(orgUnit, vars ) %>%
    summarise( n = n()) %>% pull(n) %>% max

nonMissing = dTs %>%
    filter( period %in% study_period ) %>%
    as_tibble %>%
      pivot_wider(
                 names_from = "vars",
                 values_from = "original" ) %>%
    group_by( orgUnit ) %>%
    # mutate( intervals = 1L ) %>%
    summarise_if( is.numeric , ~ sum( !is.na(.)) )


selectMinNumFacilities = function( df , cutoff = 0 , cols = NA ){
    
    if ( all( is.na( cols ) ) )   cols = colnames( df )
    isNum = map_lgl( df[, cols ], is.numeric)
    
    df %>% 
    mutate( minNonMiss = pmap( df[, cols[isNum] ] , min ) %>% unlist ) %>%
    filter( minNonMiss >= cutoff ) %>%
    pull( orgUnit )
}

data48facilities = selectMinNumFacilities( nonMissing , 46 , 
                                 cols =   c("stock"  , "cases" )
                                 ) 

cat( 
  length( data48facilities ), 
  '(' , percent( length( data48facilities ) / nrow( nonMissing ) ) , ')' ,
  'had 48 months of data for the most frequently reported variables.' 
  )

dTs.48 = dTs %>% filter( orgUnit %in% data48facilities )



```

```{r}

may2020 = yearmonth("2020-May-1")


may2020ous = dTs %>% as_tibble() %>%
  filter( period %in% may2020 , vars %in% 'cases' ,
          original > 0 ) %>% 
  pull( orgUnit ) %>% unique 

cat('there are' , length(may2020ous) , 'facilities that reported confirmed cases in May 2020' )

```

```{r}

dTs %>% 
    # left_join( dset )
    # filter to more recent range 
    filter( orgUnit %in%  data48facilities 
            , orgUnit %in% may2020ous 
            ) %>% # may2020ous
    pivot_wider( values_from = original , names_from = vars ) %>%
    mutate( nonMalaria_Attendance = attendance - cases ) %>%
    pivot_longer( cols = c( {{ dataCols }} , nonMalaria_Attendance ) , 
                  names_to = 'vars' , values_to = 'original' ) %>%
    group_by( vars ) %>%
    summarise( total = sum( original, na.rm = TRUE ) ) %>% 

    ggplot() + 
    geom_line( aes( x = period , y = total )  ) +
    facet_wrap( ~ vars , scales = 'free' ,
                labeller = labeller( vars = label_wrap_gen(50))
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = ''  ,
          title = 'Reported Totals' ,
          subtitle = 'unadjusted, reported "as is"' ,
          caption =  'Among facilities reporting in May 2020 and having complete case data')

```

```{r}

dTs %>% 
  # left_join( dset )
   # filter to more recent range 
    filter( orgUnit %in%  data48facilities 
            , orgUnit %in% may2020ous 
            ) %>% # may2020ous
    group_by( vars ) %>%
    summarise( n = sum(!is.na( original )) ) %>% 

    ggplot() + 
    geom_line( aes( x = period , y = n )  ) +
    facet_wrap( ~ vars ,
                labeller = labeller( vars = label_wrap_gen(50))
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = ''  ,
          title = 'Data Reporting For Those Facilities that Continued to Report during Pandemic' ,
          subtitle =  'Among facilities reporting in May 2020'
    )



```

# Clean data 


### Outlier 1

```{r outlier1}

dataCols = unique( dTs$vars )

.total = length( key_size( dTs ) )

pb <- progress_bar$new( 
    format = ":current :percent  [:bar] :elapsedfull",
    total = .total, clear = FALSE, width= 50 )

dTs.mad1 =  
    dTs %>% 
    filter( orgUnit %in% unique( dTs$orgUnit )[] ) %>%
    pivot_wider( 
                 names_from = "vars",
                 values_from = "original" ) %>%
    group_by( orgUnit ) %>% 
    mutate( across( all_of( dataCols ) , 

            ~clean_ts( . ,
                      interpolate = FALSE ,
                      .clean = "MAD" ,
                      MAD = 15 # median absolute deviation > 5
                      , smallThreshold = 100 
                      , .pb = pb
                      )  
                    # , otherwise = NA )
    ) 
    ) %>% 

    pivot_longer( {{ dataCols }} , 
                  names_to =  'vars' ,
                  values_to = 'mad1' ) 


# test (count number of extreme outliers)

x = inner_join( dTs, dTs.mad1 ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName",  "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  mutate( extreme1 = !is.na(original) & is.na(mad1) )

cat( 'The number of values exceeding 15x MAD that were excluded:' , sum( x$extreme1 ) )

```

TODO: Highlight facilities and variables with extremes

### outlier 2

```{r outlier2 }

pb <- progress_bar$new( 
    format = ":current :percent  [:bar] :elapsedfull",
    total = .total, clear = FALSE, width= 50 )

dTs.mad2 =  
    dTs.mad1 %>% 
    filter( orgUnit %in% unique( dTs.mad1$orgUnit )[] ) %>%
    pivot_wider( 
                 names_from = "vars",
                 values_from = "mad1" ) %>%
    group_by( orgUnit ) %>% 
    mutate( across( all_of( dataCols ) , 

            ~clean_ts( . ,
                      interpolate = FALSE ,
                      .clean = 'MAD' ,
                      lambda = 1 , # lambda 1  ~ no transformation 
                      MAD = 10 # median absolute deviation > 5
                      , smallThreshold = 100
                      , .pb = pb
                      )  
                    # , otherwise = NA )
    ) 
    ) %>% 

    pivot_longer( {{ dataCols }} , 
                  names_to =  'vars' ,
                  values_to = 'mad2' ) 


# test (count number of extreme outliers)

x = inner_join( dTs, dTs.mad1 ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName",  "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  inner_join( dTs.mad2 ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName", "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  mutate( extreme1 = !is.na(original) & is.na(mad1) ,
          extreme2 = !is.na(mad1) & is.na(mad2) )


count( as_tibble(x), extreme1, extreme2 ) %>% 
  mutate( percent = scales::percent( n / sum(n)))

```

### outlier 3

```{r outlier3 }


pb <- progress_bar$new( 
    format = ":current :percent  [:bar] :elapsedfull",
    total = .total, clear = FALSE, width= 50 )

dTs.mad3 =  
    dTs.mad2 %>% 
    filter( orgUnit %in% unique( dTs.mad2$orgUnit )[] ) %>%
    pivot_wider( 
                 names_from = "vars",
                 values_from = "mad2" ) %>%
    group_by( orgUnit ) %>% 
    mutate( across( all_of( dataCols ) , 

            ~clean_ts( . ,
                      interpolate = FALSE ,
                      .clean = 'MAD' ,
                      lambda = 1 , # lambda 1  ~ no transformation 
                      MAD = 5 # median absolute deviation > 5
                      , smallThreshold = 100
                      , .pb = pb
                      )  
                    # , otherwise = NA )
    ) 
    ) %>% 

    pivot_longer( {{ dataCols }} , 
                  names_to =  'vars' ,
                  values_to = 'mad3' ) 


# test (count number of extreme outliers)

x = inner_join( dTs, dTs.mad1 ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName", "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  inner_join( dTs.mad2 ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName",  "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  mutate( extreme1 = !is.na(original) & is.na(mad1) ,
          extreme2 = !is.na(mad1) & is.na(mad2) )   %>%
  inner_join( dTs.mad3 ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName",  "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  mutate( extreme1 = !is.na(original) & is.na(mad1) ,
          extreme2 = !is.na(mad1) & is.na(mad2) ,
          extreme3 = !is.na(mad2) & is.na(mad3) )

count( as_tibble(x), extreme1, extreme2 , extreme3  ) %>% 
  mutate( percent = scales::percent( n / sum(n) ) )

# count( as_tibble(x), vars, extreme1, extreme2 , extreme3  ) %>%
#     # pivot_wider( 
#     #              names_from = "vars",
#     #              values_from = "n" ) %>% 
#   mutate( percent = scales::percent( n / sum(n) ) )



```

NB: Identifying outliers for microscopy is potentially problematic when there is a sudden surge of microscopy--perhaps due to RDT stockouts. The inverse correlation of RDT with Microscopy confounds outlier detection. Most months there may be few or no confirmations by microscopy. When RDT not available, the number may go way up, exceeding the average by 15x fold, or more. But these vaues are not true outliers.

### outlier STL 

```{r}

pb <- progress_bar$new( 
    format = ":current :percent  [:bar] :elapsedfull",
    total = .total, clear = FALSE, width= 50 )

dTs.stl =  
    dTs.mad3 %>% 
    filter( orgUnit %in% unique( dTs.mad3$orgUnit )[] ) %>%
    pivot_wider( 
                 names_from = "vars",
                 values_from = "mad3" ) %>%
    group_by( orgUnit ) %>% 
    mutate( across( all_of( dataCols ) , 

            ~clean_ts( . ,
                      interpolate = FALSE ,
                      .clean = 'tsclean' ,
                      lambda = 1 , # lambda 1  ~ no transformation 
                      MAD = 5 # median absolute deviation > 5
                      , smallThreshold = 100
                      , .pb = pb
                      )  
                    # , otherwise = NA )
    ) 
    ) %>% 

    pivot_longer( {{ dataCols }} , 
                  names_to =  'vars' ,
                  values_to = 'stl' ) 

dTs.clean = x %>%
  inner_join( dTs.stl ,
                by = c("orgUnit", "orgUnitName", "period", "parent", "parentName",  "leaf", "level", "levelName", "effectiveLeaf", "vars") ) %>%
  mutate( extreme1 = !is.na(original) & is.na(mad1) ,
          extreme2 = !is.na(mad1) & is.na(mad2) ,
          extreme3 = !is.na(mad2) & is.na(mad3) ,
          extremeSTL = !is.na(mad3) & is.na(stl)  )

count( as_tibble(dTs.clean), 
       extreme1, extreme2 , extreme3 , extremeSTL ) %>% 
  mutate( percent = scales::percent( n / sum(n)))

count( as_tibble(dTs.clean), 
       vars, extreme1, extreme2 , extreme3 , extremeSTL ) %>%
    # pivot_wider( 
    #              names_from = "vars",
    #              values_from = "n" ) %>% 
  mutate( algorithm = case_when(
    extreme1 ~ 'MAD 15' ,
    extreme2 ~ 'MAD 10' ,
    extreme3 ~ 'MAD 5' ,
    extremeSTL ~ 'STL' ,
    TRUE ~  'Orginal' 
  )) %>%
  select( -extreme1, -extreme2, -extreme3, -extremeSTL ) %>%
  pivot_wider( names_from =  algorithm, values_from =  n )  %>%
  kbl() %>%
  kable_styling()
  
  

saveRDS( dTs.clean , paste0(
  output.folder ,
  '/dTs.clean_', Sys.Date() , '.rds') 
)

glimpse( dTs.clean )
```

# Clean Data Charts

```{r}
clean_chart_data = dTs.clean %>% 
  filter( period %in%  study_period )

clean_chart_data %>% 
    # left_join( dset )
    # filter to more recent range 
    # filter( orgUnit %in%  data48facilities
    #         , orgUnit %in% may2020ous
    #         ) %>%
    select( - original, -mad1, -mad2, -extreme1, - extreme2, 
            -mad3, -extreme3, -extremeSTL ) %>%
    pivot_wider( 
      values_from = stl , names_from = vars ) %>%
    mutate( nonMalaria_Attendance = attendance - cases ) %>%
    pivot_longer( cols = c( {{ dataCols }} , nonMalaria_Attendance ) , 
                  names_to = 'vars' , values_to = 'original' ) %>%
    group_by( vars ) %>%
    summarise( total = sum( original, na.rm = TRUE ) ) %>% 

    ggplot() + 
    geom_line( aes( x = period , y = total )  ) +
    facet_wrap( ~ vars , scales = 'free' ,
                labeller = labeller( vars = label_wrap_gen(50))
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = ''  ,
          title = 'Cleaned Totals' ,
          subtitle = 'outliers removed' 
          # caption =  'Among facilities reporting in May 2020 and having complete case data'
          )
```

```{r}
clean_chart_data %>% 
   # filter to more recent range 
    # filter( orgUnit %in%  data48facilities 
    #         # , orgUnit %in% may2020ous
    #         ) %>% # may2020ous
    group_by( vars ) %>%
    summarise( n = sum(!is.na( original )) ) %>% 

    ggplot() + 
    geom_line( aes( x = period , y = n )  ) +
    facet_wrap( ~ vars ,
                labeller = labeller( vars = label_wrap_gen(50))
                ) +
    theme( legend.position = "none" ) +
    labs( y = 'No. Facilities'  , 
          x = ''  ,
          title = 'Data Reporting For Those Facilities that Continued to Report during Pandemic' 
          # , subtitle =  'Among facilities reporting in May 2020'
    )

```


```{r nonMissing_chart2_cleanData, eval=TRUE }

data_histogram( dTs.clean %>% filter( period %in% study_period ), 
                study_period )

```
